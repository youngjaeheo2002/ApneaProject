{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "class TimeSeriesCNN(nn.Module):\n",
    "    def __init__(self, K):\n",
    "        super(TimeSeriesCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Updated the input size for the dense layer based on the conv layer calculations\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128 * 124, 512),  # Updated size\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, K)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.conv_layers(X)\n",
    "        out = out.view(out.size(0), -1)  # Flatten the output for the dense layer\n",
    "        out = self.dense_layers(out)\n",
    "        return out\n",
    "\n",
    "def stackData(names_data_and_targets):\n",
    "    res_data = np.empty((0,1000))\n",
    "    res_target = np.empty((0,1))\n",
    "\n",
    "    for item in names_data_and_targets:\n",
    "        data = item['data']\n",
    "        target = item['target']\n",
    "\n",
    "        res_data = np.vstack((res_data,data))\n",
    "        res_target = np.vstack((res_target,target))\n",
    "\n",
    "    return res_data,res_target\n",
    "\n",
    "def batch_gd(model,criterion,optimizer,train_loader,test_loader,epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    for it in range(epochs):\n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "\n",
    "        for inputs,targets in train_loader:\n",
    "            \n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            targets = targets.squeeze()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss= criterion(outputs,targets)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        #get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = []\n",
    "\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            targets = targets.squeeze()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs,targets)\n",
    "\n",
    "            test_loss.append(loss.item())\n",
    "\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        #save losses\n",
    "\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "        Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "\n",
    "    return train_losses,test_losses, model\n",
    "def turnToBinary(targets):\n",
    "    res = np.zeros(shape = (targets.shape))\n",
    "\n",
    "    for i in range(len(targets)):\n",
    "        if targets[i][0] > 0:\n",
    "            res[i][0] = 1\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, name,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    '''\n",
    "    the following is test code'''\n",
    "    print('hello')\n",
    "\n",
    "    #load the pickle dictionary\n",
    "\n",
    "        # Read and deserialize from file\n",
    "    with open('./data_and_targets_test.pkl', 'rb') as f:\n",
    "        arr = pickle.load(f)\n",
    "    split_index = math.ceil(len(arr) * 0.6)\n",
    "\n",
    "    training_data = arr[:split_index]\n",
    "    testing_data = arr[split_index:]\n",
    "\n",
    "    training_data,training_target = stackData(training_data)\n",
    "    testing_data,testing_target = stackData(testing_data)\n",
    "\n",
    "    #turn this classification problem into binary classification\n",
    "    training_target = turnToBinary(training_target)\n",
    "    testing_target = turnToBinary(testing_target)\n",
    "\n",
    "    #loss and optimizer\n",
    "    model = TimeSeriesCNN(2)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    #define batch size\n",
    "    batch_size = 128\n",
    "\n",
    "    #initilize training data and target tensors and dataset\n",
    "    training_data_tensor = torch.tensor(training_data,dtype = torch.float32)\n",
    "    training_target_tensor = torch.tensor(training_target,dtype=torch.long)\n",
    "    training_dataset = TensorDataset(training_data_tensor,training_target_tensor)\n",
    "\n",
    "    #create training dataloader\n",
    "    train_loader = DataLoader(dataset = training_dataset,batch_size=batch_size, shuffle = True)\n",
    "\n",
    "    #initialize testing data and target tensors and dataset\n",
    "    testing_data_tensor = torch.tensor(testing_data,dtype = torch.float32)\n",
    "    testing_target_tensor = torch.tensor(testing_target,dtype = torch.long)\n",
    "    testing_dataset = TensorDataset(testing_data_tensor,testing_target_tensor)\n",
    "\n",
    "    #create testing dataloader\n",
    "    test_loader = DataLoader(dataset = testing_dataset,batch_size=batch_size,shuffle = True)\n",
    "    \n",
    "\n",
    "    #set epochs \n",
    "    epochs = 10\n",
    "\n",
    "\n",
    "    train_losses, test_losses, model = batch_gd(model=model,criterion=criterion,optimizer=optimizer,train_loader=train_loader,test_loader=test_loader,epochs=epochs)\n",
    "\n",
    "    \n",
    "    torch.save(model.state_dict(),\"ANNE_PPG_CNN.pt\")\n",
    "    \n",
    "    #Record accuracy\n",
    "    model.eval()\n",
    "    n_correct = 0.\n",
    "    n_total = 0.\n",
    "\n",
    "    for inputs,targets in train_loader:\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        targets = targets.squeeze()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _,predictions = torch.max(outputs,1)\n",
    "\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    train_acc = n_correct/n_total\n",
    "\n",
    "    n_correct = 0.\n",
    "    n_total = 0.\n",
    "\n",
    "    for inputs,targets in test_loader:\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        targets = targets.squeeze()\n",
    "        outputs= model(inputs)\n",
    "\n",
    "        _,predictions= torch.max(outputs,1)\n",
    "\n",
    "        n_correct += (predictions == targets).sum().item()\n",
    "\n",
    "        n_total += targets.shape[0]\n",
    "\n",
    "    test_acc = n_correct/n_total\n",
    "\n",
    "    print(f\"Train acc : {train_acc:.4f}, Test acc : {test_acc:.4f}\")\n",
    "\n",
    "    #print confusion matrix\n",
    "\n",
    "    x_test = testing_data\n",
    "    y_test = testing_target\n",
    "    p_test = np.array([])\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        targets = targets.squeeze()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get prediction\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        # update p_test\n",
    "        p_test = np.concatenate((p_test, predictions.cpu().numpy()))\n",
    "    cm = confusion_matrix(y_test, p_test)\n",
    "    plot_confusion_matrix(cm, list(range(2)),'./cm.png')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
